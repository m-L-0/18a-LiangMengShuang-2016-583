{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jpdn\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# 下载MNIST数据集并生成DataSet对象\n",
    "# 使用OneHot编码处理标记\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32  #批次\n",
    "LEARNING_RATE=0.01 #学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Graph().as_default() as g:\n",
    "    # 输入、标记占位符\n",
    "    inputs = tf.placeholder(shape=[None, 784], dtype=tf.float32)\n",
    "    labels = tf.placeholder(shape=[None, 10], dtype=tf.float32)\n",
    "    \n",
    "    #隐藏层与输出层\n",
    "    hidden_output=tf.keras.layers.Dense(128,activation=tf.nn.relu)(inputs)\n",
    "    logits=tf.keras.layers.Dense(10,activation=None)(hidden_output)\n",
    "    output=tf.nn.softmax(logits)\n",
    "    \n",
    "    loss=tf.reduce_mean(-tf.reduce_sum(labels*tf.log(output+1e-17),axis=1))\n",
    "    acc=tf.reduce_mean(tf.cast(tf.equal(tf.argmax(output,axis=1),tf.argmax(labels,axis=1)),tf.float32))\n",
    "    optim=tf.train.GradientDescentOptimizer(learning_rate=LEARNING_RATE)\n",
    "    train_op=optim.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step     0, loss 2.2629, acc 0.0940\n",
      "step   500, loss 0.6723, acc 0.8528\n",
      "step  1000, loss 0.4900, acc 0.8849\n",
      "step  1500, loss 0.5781, acc 0.8986\n",
      "step  2000, loss 0.4700, acc 0.9072\n",
      "step  2500, loss 0.3405, acc 0.9128\n",
      "step  3000, loss 0.1988, acc 0.9166\n",
      "step  3500, loss 0.1722, acc 0.9176\n",
      "step  4000, loss 0.0807, acc 0.9210\n",
      "step  4500, loss 0.0953, acc 0.9232\n",
      "step  5000, loss 0.1165, acc 0.9270\n",
      "step  5500, loss 0.2415, acc 0.9296\n",
      "step  6000, loss 0.2103, acc 0.9287\n",
      "step  6500, loss 0.3982, acc 0.9333\n",
      "step  7000, loss 0.1803, acc 0.9347\n",
      "step  7500, loss 0.5507, acc 0.9337\n",
      "step  8000, loss 0.1765, acc 0.9381\n",
      "step  8500, loss 0.0954, acc 0.9377\n",
      "step  9000, loss 0.1439, acc 0.9397\n",
      "step  9500, loss 0.2969, acc 0.9402\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10000):\n",
    "        batch_images,batch_labels=mnist.train.next_batch(BATCH_SIZE)\n",
    "        res_loss,_=sess.run([loss,train_op],feed_dict={inputs:batch_images,labels:batch_labels})\n",
    "        if step %500==0:\n",
    "            accs=[]\n",
    "            for j in range(10000//BATCH_SIZE):\n",
    "                batch_images,batch_labels=mnist.test.next_batch(BATCH_SIZE)\n",
    "                res_acc=sess.run(acc,feed_dict={inputs:batch_images,labels:batch_labels})\n",
    "                accs.append(res_acc)\n",
    "            m_acc=np.mean(accs)\n",
    "            print('step %5d, loss %2.4f, acc %.4f' % (step, res_loss, m_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
